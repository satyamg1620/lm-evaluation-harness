[build-system]
requires = ["setuptools>=40.8.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "lm_eval"
version = "0.4.5"
authors = [{ name = "EleutherAI", email = "contact@eleuther.ai" }]
description = "A framework for evaluating language models"
readme = "README.md"
classifiers = [
    "Development Status :: 3 - Alpha",
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
]
requires-python = "<3.13,>=3.10"
license = { "text" = "MIT" }
dependencies = [
    "accelerate==1.0.1",
    "evaluate==0.4.3",
    "datasets==3.1.0",
    "jsonlines==4.0.0",
    "numexpr==2.10.1",
    "peft==0.13.2",
    "pybind11==2.13.6",
    "pytablewriter==1.2.0",
    "rouge-score==0.1.2",
    "sacrebleu==2.4.3",
    "scikit-learn==1.5.2",
    "sqlitedict==2.1.0",
    "torch==2.6.0",
    "tqdm-multiprocess==0.0.11",
    "transformers==4.45.2",
    "zstandard==0.23.0",
    "dill==0.3.8",
    "word2number==1.1",
    "more_itertools==10.5.0",
    "unitxt==1.15.7",
    "jiwer==3.0.5",
    "boto3==1.36.11",
]

[tool.setuptools.packages.find]
include = ["lm_eval*"]

# required to include yaml files in pip installation
[tool.setuptools.package-data]
lm_eval = ["**/*.yaml", "tasks/**/*"]

[project.scripts]
lm-eval = "lm_eval.__main__:cli_evaluate"
lm_eval = "lm_eval.__main__:cli_evaluate"

[project.urls]
Homepage = "https://github.com/EleutherAI/lm-evaluation-harness"
Repository = "https://github.com/EleutherAI/lm-evaluation-harness"

[project.optional-dependencies]
api = [
    "requests==2.32.3",
    "aiohttp==3.10.10",
    "tenacity==9.0.0",
    "tqdm==4.66.6",
    "tiktoken==0.12.0",
]
ibm_watsonx_ai = ["ibm-watsonx-ai==1.1.23"]

[tool.ruff.lint]
extend-select = ["I"]

[tool.ruff.lint.isort]
lines-after-imports = 2
known-first-party = ["lm_eval"]

[tool.ruff.lint.extend-per-file-ignores]
"__init__.py" = ["F401", "F402", "F403"]
"utils.py" = ["F401"]
